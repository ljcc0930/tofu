{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhilif/anaconda3/envs/tf/lib/python3.9/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "from scipy.stats import hmean\n",
    "import numpy as np\n",
    "from scipy.stats import sem, hmean, ks_2samp\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from aggregate_eval_stat import get_forget_quality, get_model_utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "95\n",
      "95\n",
      "95\n",
      "95\n",
      "90\n",
      "90\n",
      "90\n",
      "90\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "95\n",
      "95\n",
      "95\n",
      "95\n",
      "90\n",
      "90\n",
      "90\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os \n",
    "import copy \n",
    "import pandas as pd\n",
    "import json \n",
    "from natsort import natsorted \n",
    "wds = ['0.01']\n",
    "model_family=['llama2-7b', 'phi']\n",
    "lr_map = {'llama2-7b': '1e-05', 'phi': '2e-05'}\n",
    "ft_base_dir = '../paper_models/final_ft_noLORA_5_epochs_inst_lr{}_{}_full_wd{}/checkpoint-625'\n",
    "retain_base_dir = '../paper_models/final_ft_noLORA_5_epochs_inst_lr{}_{}_{}_wd{}'\n",
    "unlearn_algs = ['grad_ascent', 'grad_diff', 'idk', 'KL']\n",
    "forget_ratios=['01', '05', '10']\n",
    "df_cols = [\"ROUGE Real Authors\", \"Prob. Real Authors\", \"Truth Ratio Real Authors\", \\\n",
    "    \"ROUGE Real World\", \"Prob. Real World\", \"Truth Ratio Real World\", \"ROUGE Retain\", \\\n",
    "    \"Prob. Retain\", \"Truth Ratio Retain\", \"ROUGE Forget\", \"Prob. Forget\", \\\n",
    "    \"Truth Ratio Forget\", \"Model Utility\", \"Forget Quality\", \"Method\", \"Submitted By\",\n",
    "    \"Epoch\"\n",
    "]\n",
    "for model in model_family:\n",
    "    lr = lr_map[model]\n",
    "    for forget_ratio in forget_ratios:\n",
    "        df = pd.DataFrame(columns=['Method'])\n",
    "\n",
    "        for wd in wds:\n",
    "            for unlearn_alg in unlearn_algs:\n",
    "                ft_dir = ft_base_dir.format(lr, model, wd)\n",
    "                unlearn_result_dir = f'{ft_dir}/{unlearn_alg}_1e-05_forget{forget_ratio}'\n",
    "                # get all subfolder with name checkpoint in unlearn_result_dir\n",
    "                unlearn_res_files  = glob.glob(f'{unlearn_result_dir}/checkpoint-*/eval_results/ds_size300/eval_log_aggregated.json')\n",
    "                unlearn_res_files = natsorted(unlearn_res_files)\n",
    "                retain_ratio = int(100-int(forget_ratio))\n",
    "                print(retain_ratio)\n",
    "                retain_dir = retain_base_dir.format(lr, model, f'retain{retain_ratio}', wd)\n",
    "                retain_res_file = glob.glob(f'{retain_dir}/checkpoint-*/eval_results/ds_size300/eval_log_aggregated.json')\n",
    "                # Filter out only directories\n",
    "                # subfolders = [f for f in ckpt_dirs if os.path.isdir(f)]\n",
    "                # print(unlearn_result_dir)\n",
    "                # print(retain_res_file)\n",
    "                retain_res = json.load(open(retain_res_file[0]))\n",
    "                for i, ckpt_file in enumerate(unlearn_res_files):\n",
    "                    ckpt_res = json.load(open(ckpt_file))\n",
    "                    model_utility = get_model_utility(ckpt_res)\n",
    "                    forget_quality = get_forget_quality(ckpt_res, retain_res)\n",
    "                    # print(ckpt_file, forget_quality)\n",
    "                    df_row = copy.deepcopy(model_utility)\n",
    "                    df_row['Forget Quality'] = forget_quality['Forget Quality']\n",
    "                    df_row['Method'] = unlearn_alg\n",
    "                    df_row['Submitted By'] = 'Baseline'\n",
    "                    df_row['Epoch'] = int(i)\n",
    "                    df = pd.concat([df, pd.DataFrame([df_row])], ignore_index=True)\n",
    "        \n",
    "        df.to_csv(f'{model}_{forget_ratio}.csv', index=False)\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Forget Quality': 0.5568991019617135,\n",
       " 'KS Test PVal Forget': 0.5568991019617135,\n",
       " 'KS Test Forget': 0.11}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# load json\n",
    "with open('/home/zhilif/tofu/debug/phi_retain90/checkpoint-0/eval_log_aggregated.json') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "get_model_utility(data)\n",
    "get_forget_quality(data, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json to panda \n",
    "import pandas as pd\n",
    "df = pd.read_json('/home/zhilif/tofu/paper_models/final_ft_noLORA_5_epochs_inst_lr2e-05_phi_full/checkpoint-625/grad_ascent_1e-05_forget01/checkpoint-5/eval_results/ds_size300/eval_log_aggregated.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_gt_loss 300\n",
      "gt_loss 300\n",
      "num_token_gt 300\n",
      "generated_text 300\n",
      "rouge1_recall 300\n",
      "rougeL_recall 300\n",
      "average_perturb_loss 300\n",
      "avg_paraphrased_loss 300\n",
      "truth_ratio 300\n",
      "paraphrased_loss 300\n",
      "perturb_loss 300\n",
      "num_token_paraphrased 300\n",
      "num_token_perturb 300\n",
      "avg_gt_loss 100\n",
      "gt_loss 100\n",
      "num_token_gt 100\n",
      "generated_text 100\n",
      "rouge1_recall 100\n",
      "rougeL_recall 100\n",
      "average_perturb_loss 100\n",
      "avg_paraphrased_loss 100\n",
      "truth_ratio 100\n",
      "paraphrased_loss 100\n",
      "perturb_loss 100\n",
      "num_token_paraphrased 100\n",
      "num_token_perturb 100\n",
      "avg_gt_loss 117\n",
      "gt_loss 117\n",
      "num_token_gt 117\n",
      "generated_text 117\n",
      "rouge1_recall 117\n",
      "rougeL_recall 117\n",
      "average_perturb_loss 117\n",
      "avg_paraphrased_loss 117\n",
      "truth_ratio 117\n",
      "paraphrased_loss 117\n",
      "perturb_loss 117\n",
      "num_token_paraphrased 117\n",
      "num_token_perturb 117\n",
      "avg_gt_loss 40\n",
      "gt_loss 40\n",
      "num_token_gt 40\n",
      "generated_text 40\n",
      "rouge1_recall 40\n",
      "rougeL_recall 40\n",
      "average_perturb_loss 40\n",
      "avg_paraphrased_loss 40\n",
      "truth_ratio 40\n",
      "paraphrased_loss 40\n",
      "perturb_loss 40\n",
      "num_token_paraphrased 40\n",
      "num_token_perturb 40\n"
     ]
    }
   ],
   "source": [
    "# iterate through the df['eval_log.json']\n",
    "for k, v in df['eval_log.json'].items():\n",
    "    print(k, len(v.keys()))\n",
    "\n",
    "for k, v in df['eval_real_author_wo_options.json'].items():\n",
    "    print(k, len(v.keys()))\n",
    "\n",
    "for k, v in df['eval_real_world_wo_options.json'].items():\n",
    "    print(k, len(v.keys()))\n",
    "\n",
    "for k, v in df['eval_log_forget.json'].items():\n",
    "    print(k, len(v.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path \n",
    "\n",
    "model_family = ['llama2-7b', 'phi']\n",
    "splits = ['full', 'retain90', 'retain95', 'retain99']\n",
    "wds = [0, 0.01]\n",
    "lr_map = {\n",
    "    'llama2-7b': '1e-05',\n",
    "    'phi': '2e-05'\n",
    "}\n",
    "ckpt_dict = {\n",
    "    'full': 625,\n",
    "    'retain90': 562,\n",
    "    'retain95': 593,\n",
    "    'retain99': 618\n",
    "}\n",
    "for model in model_family:\n",
    "    lr = lr_map[model]\n",
    "    for split in splits:\n",
    "        for wd in wds:\n",
    "            model_name = f'ft_epoch5_lr{lr}_{model}_{split}_wd{wd}'\n",
    "            model_path = f'/home/zhilif/tofu/paper_models/{model_name}/checkpoint-{ckpt_dict[split]}'\n",
    "            eval_results = f'{model_path}/eval_results'\n",
    "            target_path = f'/home/zhilif/tofu/data/{model_name}/'\n",
    "            Path(target_path).mkdir(parents=True, exist_ok=True)\n",
    "            # copy result_path to /home/zhilif/tofu/data\n",
    "            os.system(f'cp -r {eval_results} {target_path}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
